** webigator
**   by Graham Neubig
**   neubig at gmail dot com

このプログラムは大規模なテキストから有用な情報を取り出すプログラムです。例えば、このプログラムは特に震災時において有用な情報を取り出すために作られたもので、

＊避難所、給水所、充電所の情報を提供するテキスト
＊安否情報を提供するテキスト
＊助けを求めているテキスト

今のところ特にTwitter上のツィートをフィルタリングし、自分の探したい情報が入っているものを見つける仕組みになっています。手法などは以下の論文に説明してあります：

Graham Neubig, 森 信介.
能動学習による効率的な情報フィルタリング
言語処理学会第18回年次大会(NLP2012). 広島. 2012年3月.
http://www.phontron.com/paper/neubig12nlp-saigai.pdf

-------------- インストール -------------------

プログラムはLinuxで動作確認をしています。MacやCygwinなどでも動く可能性は高いです。割と多くのライブラリに依存しています。Ubuntuでインストールをする前に、まずサーバーが依存するライブラリ（BoostとXML-RPC）をインストールします：

sudo apt-get install libboost-all-dev libxmlrpc-c3-dev

また、Perlのクライアントが依存するXML::RPCもインストールします。

cpan XML::RPC

その次、サーバーをビルドします：

autoreconf -i
./configure
make

これがうまく行けば：
src/bin/webigator --help
でヘルプを表示することができます。うまく行かない可能性が高いので、その場合はGrahamへ連絡を下さい。

--------------- 作業の流れ -------------------

インストールが無事終わったら、次は作業に移ることができます。まずはサーバをを立ち上げます。

$ src/bin/webigator

次はクライアントを立ち上げます。ここにある設定として、data_fileは検索したい膨大なデータです。今のところ、東日本大震災ビッグデータワークショップのtsv形式ツイートデータを入力と想定しています。save_fileは「有用」「有用でない」というラベル付きデータを出力するファイルです。

$ script/label-examples.pl -data_file tweets.tsv -save_file output.tsv

このプログラムを実行したら、検索したいキーワードを１個以上入力する。キーワードを入力し終わったら、何も入力せずに「Enter」を押す。

> Enter a keyword (or just press 'enter' to finish): 
> 充電
> Enter a keyword (or just press 'enter' to finish): 
> 給水
> Enter a keyword (or just press 'enter' to finish): 

その次、プログラムはデータを読み込んでくれる。データが大きければ、時間がかかることはあります（検索キーワードの頻度などによりますが、平均的に1分に100万ツイートをのペースです）。

> Loading data from tweets.tsv (. == 10,000 sentences, ! == 100,000 sentences)
> .....

次は、有用なテキストと有用でないテキストを手でラベル付けしながら特定することにする。テキストが１個ずつ提供されて、「有用」と判定したものは「y」、「有用でない」と判定したものは「n」を入力する。ラベルをつければつけるほど、プログラムが学習してくれて、より的確に情報を提供してくれるようになる仕組みになっている。

> ケータイの電源を充電したい。
> Is this tweet useful? y/n: n
> 仙台駅前の隣のローソンで給水所があるよ！
> Is this tweet useful? y/n: y

途中でさらにキーワードを入れたい時はプログラムを「Ctrl+C」で終了させて、最初から動かすことができる。ラベルづけ全体が終わった時はwebigatorサーバを終了させる。

-------------------- API -------------------------

Perlプログラムでもwebigatorサーバを利用できるが、最終的にWebインターフェースを作るのが目的です。これをするために、webigatorサーバはAPIを提供しています。XML-RPCというRPC形式を利用しており、これを使うとどの言語から簡単にサーバを操作することができます。label-examples.plを見ると使い方の例がありますが、簡単に説明すると：

***** キーワードを追加
add_keyword:
    id = データのID （整数）
    text = データ自体 (文字列)
    lab = このキーワードは「有用」を指す場合は「1」、「有用でない」の場合は「0」

***** まだラベルを追加していない検索対象のデータを追加
add_unlabeled:
    id = データのID （整数）
    text = データ自体 (文字列)

***** 人手でラベルされたデータを追加
add_labeled:
    id = データのID （整数）
    text = データ自体 (文字列)
    lab = このキーワードは「有用」を指す場合は「1」、「有用でない」の場合は「0」

***** 今サーバが知っている検索対象のデータの中で一番スコアの高いものを返す
pop_best:

***** 今サーバが知っている検索対象のデータのスコアを計算し直す。
***** add_keywordやadd_labeled後に呼ぶとより正確な例を返すことができる。
rescore:

--------------- 改善点 ------------------

* スレッドのサポートはまだ不十分
* スコアリング関数の改善
* Webインターフェースの構築
